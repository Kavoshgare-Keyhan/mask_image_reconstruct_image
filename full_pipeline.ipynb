{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f56684f7",
   "metadata": {},
   "source": [
    "# Episodic Memory and Generative Completion - Full Pipeline\n",
    "\n",
    "1. Train VQ-VAE Model\n",
    "2. Apply the trained model on entire images and store codebook as quantizers, latent spaces as indices, and then reconstruct images\n",
    "3. Train a classifier model\n",
    "4. Train a transformer, here distilbert\n",
    "5. Ensemble all together to see the performance of transformer on different type of masking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034062bf",
   "metadata": {},
   "source": [
    "> Set up essentials\n",
    "\n",
    "Including:\n",
    "1. modules and libraries\n",
    "2. functions\n",
    "3. config data\n",
    "4. etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6e6d8c",
   "metadata": {},
   "source": [
    "## Step 1 - Train VQVAE Model \n",
    "\n",
    "- Obtain best model\n",
    "- Obtain best hyperparameters\n",
    "- Record Test Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eca04a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, yaml, optuna, mlflow, subprocess, json\n",
    "from torch import nn, optim\n",
    "from vqvae import FlatVQVAE\n",
    "from utils import CustomImageNetDataV2, CustomLoader\n",
    "from torch import distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data.distributed import DistributedSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fae4a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse config file\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config_data = yaml.full_load(f)\n",
    "\n",
    "img_train_dir = config_data['path']['image_net_train']\n",
    "img_test_dir = config_data['path']['image_net_test']\n",
    "img_val_dir = config_data['path']['image_net_val']\n",
    "model_path = config_data['path']['vqvae_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e682c156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs below 30% usage:\n",
      "GPU 0: 0.15% used\n"
     ]
    }
   ],
   "source": [
    "def get_available_gpus(threshold_percent=20):\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=memory.used,memory.total', '--format=csv,nounits,noheader'],\n",
    "                                stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        lines = result.stdout.strip().split('\\n')\n",
    "        usage = [(i, int(u.split(',')[0]) / int(u.split(',')[1]) * 100) for i, u in enumerate(lines)]\n",
    "        available = [(i, round(percent, 2)) for i, percent in usage if percent < threshold_percent]\n",
    "        print(f\"GPUs below {threshold_percent}% usage:\")\n",
    "        for i, p in available:\n",
    "            print(f\"GPU {i}: {p}% used\")\n",
    "        return [i for i, _ in available]\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking GPU status: {e}\")\n",
    "        return []\n",
    "\n",
    "# Example usage\n",
    "available_gpu_ids = get_available_gpus(threshold_percent=30)\n",
    "\n",
    "# Manual selection (for now, just pick the first one if available)\n",
    "selected_gpu_ids = available_gpu_ids if available_gpu_ids else [0]\n",
    "device = torch.device(f\"cuda:{selected_gpu_ids[0]}\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3514ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_distributed():\n",
    "    '''\n",
    "    Useful to integrate in notebook\n",
    "    '''\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        dist.init_process_group(backend=\"nccl\")\n",
    "        local_rank = int(os.environ.get(\"LOCAL_RANK\", 0))\n",
    "        torch.cuda.set_device(local_rank)\n",
    "        print(f\"Distributed initialized. Using GPU {local_rank}\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_loader(dataset, batch_size, shuffle, distributed):\n",
    "    if distributed:\n",
    "        return CustomLoader(dataset, batch_size=batch_size, shuffle = shuffle, distributed = distributed).data_loader\n",
    "    else:\n",
    "        return CustomLoader(dataset, batch_size=batch_size, shuffle = shuffle).data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd388906",
   "metadata": {},
   "source": [
    "> Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00617521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“‚ Load datasets\n",
    "train_set = CustomImageNetDataV2(image_dir = img_train_dir, image_type = 'original', folder_label = 'int_id')\n",
    "val_set = CustomImageNetDataV2(image_dir = img_val_dir, image_type = 'original', folder_label = 'int_id')\n",
    "test_set = CustomImageNetDataV2(image_dir = img_test_dir, image_type = 'original', folder_label = 'int_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720e4c2b",
   "metadata": {},
   "source": [
    "> Use Optuna to find best hyperparameters and log them via MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b8c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§  Optuna objective function\n",
    "def objective(trial):\n",
    "    # ðŸ”§ Hyperparameters\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-3, log=True) # samples values logarithmically, favoring smaller values\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True) # samples values logarithmically, favoring smaller values\n",
    "    latent_loss_weight = trial.suggest_float(\"latent_loss_weight\", 0.1, 2.0, log=True) # use logarithmic sampling instead of linear increments since parameter behaves non-linearly â€” small changes at low values have big effects, but want to explore larger ones as well\n",
    "    diversity_loss_weight = trial.suggest_float(\"diversity_loss_weight\", 0.0, 1.0) # samples linearly without discrimination between values in the specified range\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128]) # picks one from the list\n",
    "    num_epochs = trial.suggest_int('num_epochs', 10, 50) # picks an integer, but doesnâ€™t â€œtry allâ€ in sequence.\n",
    "\n",
    "    distributed = dist.is_available() and dist.is_initialized()\n",
    "    shuffle = not distributed\n",
    "\n",
    "    train_loader = get_loader(train_set, batch_size, shuffle, distributed)\n",
    "    val_loader = get_loader(val_set, batch_size, False, distributed)\n",
    "\n",
    "    # ðŸ§  Model\n",
    "    model = FlatVQVAE().to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.parallel.DataParallel(model)\n",
    "    # if distributed:\n",
    "    #     model = DDP(model, device_ids=[device]) # useful for .py cript execute by torchrun \"torchrun --nproc_per_node=4 train.py\" or python -m torch.distributed.launch\n",
    "\n",
    "    recon_criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3)\n",
    "\n",
    "    mlflow.start_run(run_name=f\"Optuna_Trial_{trial.number}\")\n",
    "    mlflow.log_params(trial.params)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, _ in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon, latent_loss, diversity_loss, _ = model(inputs)\n",
    "            recon_loss = recon_criterion(recon, inputs)\n",
    "            loss = recon_loss + latent_loss_weight * latent_loss + diversity_loss_weight * diversity_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, _ in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                recon, latent_loss, diversity_loss, _ = model(inputs)\n",
    "                recon_loss = recon_criterion(recon, inputs)\n",
    "                loss = recon_loss + latent_loss_weight * latent_loss + diversity_loss_weight * diversity_loss\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "        mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), f\"{model_path}/best_vqvae_model_trial_{trial.number}.pth\")\n",
    "    mlflow.pytorch.log_model(model, artifact_path=\"vqvae_model\")\n",
    "\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc22d8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 09:54:00,252] A new study created in memory with name: no-name-6c8a42dd-ae53-4938-a2f9-8c8a98a77cb4\n",
      "/home/mohsen/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:84.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "best_trial = study.best_trial\n",
    "print(\"Best Trial:\")\n",
    "for k, v in best_trial.params.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "with open(f\"{model_path}/best_vqvae_params_trial_{best_trial.number}.json\", 'w') as f:\n",
    "    json.dump(best_trial.params, f, indent=4)\n",
    "\n",
    "# Reload best model\n",
    "model = FlatVQVAE().to(device)\n",
    "model.load_state_dict(torch.load(f\"{model_path}/best_vqvae_model_trial_{best_trial.number}.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Test loader\n",
    "test_loader = get_loader(test_set, batch_size=best_trial.params['batch_size'], shuffle=False, distributed=False)\n",
    "\n",
    "# Evaluate\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        recon, latent_loss, diversity_loss, _ = model(inputs)\n",
    "        recon_loss = nn.MSELoss()(recon, inputs)\n",
    "        loss = recon_loss + best_trial.params['latent_loss_weight'] * latent_loss + best_trial.params['diversity_loss_weight'] * diversity_loss\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6500aa4f",
   "metadata": {},
   "source": [
    "# Step 2 - Reconstruct Images\n",
    "\n",
    "- Apply trained model on test data to "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
